{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for Solar Wind Exploration\n",
    "\n",
    "In the initial phase, we want to see if we can detect FTEs using unsupervised learning, by finding a manifold for the solar wind data.\n",
    "\n",
    "The initial hypothesis is the transition matrices (Markov Matrices $M$) that can be derived from Manifolder + clustering will show distinctive clusters and transitions.  We can check accuracy by looking at the label (FTE or not?), and see if this label could have been deduced from the data itself.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful set of python includes\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Solar Wind Data, and Run Manifolder\n",
    "\n",
    "The `dataset_2` file contains \n",
    "\n",
    "Dataset-2 (THEMIS):   a list with FTEs periods and non-FTEs periods observed by THEMIS in 2007.  These are combined into one file, randomly FTE - NonFTE - FTE - FTE, NonFTE, etcâ€¦\n",
    "\n",
    "In total there are 63 FTEs and 47 non-FTEs.\n",
    "\n",
    "The time series are separated by one blank line, and each one has 1440 points in a period of 6 minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\acloninger\\GDrive\\ac2528Backup\\DocsFolder\\GitHub\\manifolder\")\n",
    "sys.path.append(r\"..\")\n",
    "\n",
    "import manifolder as mr\n",
    "from manifolder import helper as mh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "# note, you must have started the notebook in the \n",
    "\n",
    "print('loading data ...')\n",
    "df = pd.read_excel('astro_data/dataset_2.xlsx', index_col=0)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert values from loaded spreadsheet, into a numpy matrices\n",
    "# note that there is no need for the first value, which is time,\n",
    "# as it is not part of the manifold\n",
    "#\n",
    "# also, note the spreadsheet is missing a column name for `Unnamed: 13`, and the values above\n",
    "# this have the incorrect column labels; the first relevant vale is bx, which as a magnitude around 2\n",
    "#\n",
    "# note the final value of each row is the goal (0 or 1), and not part of z\n",
    "\n",
    "data_raw = df.values[:, 1:]\n",
    "print('first line of raw_data:\\n', data_raw[0, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#Load Data\n",
    "segments = np.load('themis\\segments-newdata-all.npy')\n",
    "\n",
    "# Load Labels\n",
    "labels = np.load('themis\\labels-newdata-all.npy')\n",
    "labels = np.asarray(pd.get_dummies(labels))\n",
    "\n",
    "#Load Bounding Boxes/ Event Locations\n",
    "with open('themis/bbox.pickle','rb') as f:\n",
    "    bboxes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the data, breaking out the clusters\n",
    "# i will always point to the NaN (blank line) in the dataframe,\n",
    "# and values [i-1440:i] is the snipped\n",
    "\n",
    "snippet_len = 1440\n",
    "\n",
    "# collect all line breaks (blank lines) in csv file\n",
    "#lineBreaks = [0]\n",
    "#for i in range(data_raw.shape[0]):\n",
    "#    if data_raw[i,0] != data_raw[i,0]:  # replacement of isnan, since nan != nan\n",
    "#        lineBreaks.append(i)    \n",
    "#lineBreaks.append(data_raw.shape[0])\n",
    "#\n",
    "#num_snippet = len(lineBreaks)-1\n",
    "\n",
    "\n",
    "# callect the snippets into two groups, one for each goal (target) value, 0 or 1\n",
    "# these can be easily merged\n",
    "zs_0 = []\n",
    "zs_1 = []\n",
    "\n",
    "locallabel_0 = []\n",
    "locallabel_1 = []\n",
    "snippet_index = 0;\n",
    "\n",
    "df.values[0,:]\n",
    "\n",
    "reduce_dimension = True\n",
    "\n",
    "for i in range(snippet_len,data_raw.shape[0]+1,snippet_len+1):\n",
    "    # copy the snipped, excluding the last value, which is the goal\n",
    "    snippet = data_raw[i-snippet_len:i,:-1]\n",
    "    \n",
    "    if reduce_dimension:\n",
    "        snippet = snippet[:,5]\n",
    "        snippet = snippet.reshape(snippet_len,1)\n",
    "\n",
    "    # grab the goal value from the first row of each snippet\n",
    "    goal = data_raw[i-snippet_len,-1]\n",
    "    \n",
    "    # check to make sure each snippet does not contain NaN\n",
    "    # (should not, if parsing is correct)\n",
    "    assert ~np.isnan(snippet).any(), 'oops, snippet contains a Nan!'\n",
    "    \n",
    "    print('snippet size',snippet.shape,'with goal',goal)\n",
    "    \n",
    "    snippetlabel = np.zeros(snippet_len)\n",
    "    if goal == 1:\n",
    "        bmin = int(bboxes[snippet_index][0][0])\n",
    "        bmax = int(bboxes[snippet_index][0][2])\n",
    "        snippetlabel[bmin:bmax] = 1\n",
    "    \n",
    "    if goal == 0:\n",
    "        zs_0.append( snippet )\n",
    "        locallabel_0.append( snippetlabel )\n",
    "    elif goal == 1:\n",
    "        zs_1.append( snippet )\n",
    "        locallabel_1.append( snippetlabel )\n",
    "    else:\n",
    "        assert False, 'value of goal not understood'\n",
    "        \n",
    "    snippet_index = snippet_index + 1;\n",
    "        \n",
    "\n",
    "# shuffle this lists; this should not strictly be necessary, if all the data is being used,\n",
    "# but prevents biases when shortening the list\n",
    "\n",
    "c0 = list(zip(zs_0, locallabel_0))\n",
    "random.shuffle(c0)\n",
    "zs_0, locallabel_0 = zip(*c0)\n",
    "zs_0 = list(zs_0)\n",
    "locallabel_0 = list(locallabel_0)\n",
    "\n",
    "c1 = list(zip(zs_1, locallabel_1))\n",
    "random.shuffle(c1)\n",
    "zs_1, locallabel_1 = zip(*c1)\n",
    "zs_1 = list(zs_1)\n",
    "locallabel_1 = list(locallabel_1)\n",
    "\n",
    "shorten_data = False\n",
    "\n",
    "if shorten_data:\n",
    "    zs_0 = zs_0[:20]\n",
    "    zs_1 = zs_1[:20]\n",
    "    locallabel_0 = locallabel_0[:20]\n",
    "    locallabel_1 = locallabel_1[:20]\n",
    "        \n",
    "zs = zs_0 + zs_1\n",
    "locallabel = locallabel_0 + locallabel_1\n",
    "z_breakpoint = len(zs_0)\n",
    "\n",
    "print( '\\done!')\n",
    "print( '\\t len(zs_0):',len(zs_0))\n",
    "print( '\\t len(zs_1):',len(zs_1))\n",
    "print( '\\t len(zs):',len(zs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    if reduce_dimension==False:\n",
    "        plt.plot(zs_0[i][:,5])\n",
    "    else:\n",
    "        plt.plot(zs_0[i][:,0])\n",
    "        \n",
    "    plt.plot(10*locallabel_0[i])\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    if reduce_dimension==False:\n",
    "        plt.plot(zs_1[i][:,5])\n",
    "    else:\n",
    "        plt.plot(zs_1[i][:,0])\n",
    "    plt.plot(10*locallabel_1[i])\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data has been parsed, now run Manifolder\n",
    "\n",
    "dim=8\n",
    "H = 160\n",
    "step_size = 20\n",
    "nbins = 10\n",
    "ncov = 10\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# create manifolder object\n",
    "manifolder = mr.Manifolder(dim=dim,H=H,step_size=step_size,nbins=nbins, ncov=ncov)\n",
    "\n",
    "# add the data, and fit (this runs all the functions)\n",
    "manifolder.fit_transform(zs, parallel=False)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print('\\n\\t Program Executed in', str(np.round(elapsed_time, 2)), 'seconds')  # about 215 seconds (four minutes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locallabel_downsample = np.empty(0, float)\n",
    "for i in range(len(locallabel)):\n",
    "    x = locallabel[i]\n",
    "    x = x[0:x.shape[0]-H]\n",
    "    x = x[::step_size]\n",
    "\n",
    "    locallabel_downsample = np.append(locallabel_downsample,x,0)\n",
    "    \n",
    "Psi = manifolder.Psi[:,0:manifolder.Dim]\n",
    "    \n",
    "print(locallabel_downsample.shape)\n",
    "print(Psi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(manifolder.Psi[:,0],manifolder.Psi[:,2],c=locallabel_downsample,cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "singledim = []\n",
    "for snippet in zs:\n",
    "    singledim.append(snippet[:,0])\n",
    "\n",
    "results = []\n",
    "for i in range(1000):\n",
    "    kmeans_orig = KMeans(n_clusters=2).fit(singledim)\n",
    "    found = False\n",
    "    for temp in results:\n",
    "        if (kmeans_orig.labels_ == temp[0]).all() or (kmeans_orig.labels_ != temp[0]).all():\n",
    "            temp[1] += 1\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        results.append([kmeans_orig.labels_, 1])\n",
    "results = sorted(results, key=lambda array: array[1])\n",
    "print(results)\n",
    "cluster_out = results[-1][0]\n",
    "print(cluster_out)\n",
    "numCorrect = 0\n",
    "for i in range(len(zs_0)):\n",
    "    if cluster_out[i] == 0:\n",
    "        numCorrect += 1\n",
    "for i in range(len(zs_0)+1, len(zs)):\n",
    "    if cluster_out[i] == 1:\n",
    "        numCorrect += 1\n",
    "print(max(numCorrect, len(zs)-numCorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
